{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9674679",
   "metadata": {},
   "source": [
    "# CSC475/575 Spring 2024 - Assignment 4\n",
    "\n",
    "This assignment covers topics related to genre classification and tag annotation  \n",
    "\n",
    "* A4.1: Dataset preparation  \n",
    "* A4.2: Feature extraction + SVM \n",
    "* A4.3: Classifier comparison with classification report and confusion matrix \n",
    "* A4.4: Misclassification audio \n",
    "* A4.5: musicnn tags -> naive bayes classifier \n",
    "\n",
    "Each question is worth 2 points for a total of 10 points for the assignment. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1748e6",
   "metadata": {},
   "source": [
    "#### **Question A4.1 (basic): Dataset preparation** \n",
    " \n",
    "You can work on this particular question in coordination with other students or members of your group as it is mostly logistics but useful to know. The next two assignements are based on the dataset you will prepare. We will be using FMA: A Dataset For Music Analysis https://github.com/mdeff/fma. The repository contains the datasets as well as a various code examples for different tasks. You are welcome to use/consult/modify any code from the repository. \n",
    "\n",
    "You will need to download the fma small dataset (fma_small.zip) from the repository which contains a balanced dataset with 8 genres and 1000 tracks per genre. The size of the dataset is 7.2GB. Create a new fma-smaller dataset that consists of 4 genres, 1000 tracks per genre in which each track is 6 seconds instead of 30 seconds. You will need to load the 30 second tracks and write the 6 second short tracks to disk. For the remainder of the assignment and the next assignment you will be using this smaller dataset so that it takes less hard disk space and is easier to deal with. \n",
    "The four genres you will use are Instrumental, HipHop, Rock, and Folk. Show that your code works by plotting the time domain waveforms of a HipHop track and a Folk track from the new fma_smaller dataset. Once you have things working you can erase the original fma_small stuff to free up space if needed.\n",
    "\n",
    "\n",
    "Note: librosa uses audioread in the backend which can use many native libraries, e.g. ffmpeg resampling is very slow --> use kaiser_fast\n",
    "Use .wav files for the smaller dataset \n",
    "\n",
    " (**Basic: 2 points**)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5ed6df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here \n",
    "\n",
    "#Dataset generated by group memeber Alyssa Blair, as George said that we could do that in class\n",
    "#missing four files because they're less than 30 seconds and kinda bugged\n",
    "\n",
    "#Alyssa Blair's code:\n",
    "\n",
    "# import librosa\n",
    "# import fma.utils as utils\n",
    "# import soundfile as sf\n",
    "\n",
    "# def resample_file(input_file):\n",
    "#     try:\n",
    "#         arr, sr = librosa.load(input_file)\n",
    "#         new_sample = librosa.resample(arr[:int(len(arr)/5)], orig_sr=sr, target_sr=sr, res_type=\"kaiser_fast\")  \n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(\"Error resampling file: \", input_file, e)\n",
    "#         new_sample = None\n",
    "#         sr = 0\n",
    "\n",
    "#     return new_sample, sr\n",
    "\n",
    "\n",
    "# genres = utils.load('fma_metadata/genres.csv')\n",
    "# tracks = utils.load('fma_metadata/tracks.csv')\n",
    "# features = utils.load('fma_metadata/features.csv')\n",
    "# small = tracks[tracks['set', 'subset'] <= 'small']\n",
    "\n",
    "\n",
    "# genre1 = small[small['track', 'genre_top'] == 'Instrumental'].index.values\n",
    "# genre2 = small[small['track', 'genre_top'] == 'Hip-Hop'].index.values\n",
    "# genre3 = small[small['track', 'genre_top'] == 'Rock'].index.values\n",
    "# genre4 = small[small['track', 'genre_top'] == 'Folk'].index.values\n",
    "\n",
    "# genres = {'instrumental': genre1, 'hiphop': genre2, 'rock': genre3, 'folk': genre4}\n",
    "\n",
    "\n",
    "# def filter_genre(track_ids, genre_name):\n",
    "#     counter = 0\n",
    "    \n",
    "#     for track in track_ids:\n",
    "#         track_id = str(track)\n",
    "\n",
    "#         track_name = (6 - len(track_id)) * '0' + track_id\n",
    "    \n",
    "#         input_file = f'fma_small/{track_name[:3]}/{track_name}.mp3'\n",
    "#         audio, sr = resample_file(input_file)\n",
    "\n",
    "#         if audio is None:\n",
    "#             continue\n",
    "        \n",
    "#         output_file = f'fma_smaller/{genre_name}/{track_name}.wav'\n",
    "#         sf.write(output_file, audio, sr)\n",
    "    \n",
    "#         # counter to keep track of progress\n",
    "#         counter += 1\n",
    "\n",
    "#         if counter % 200 == 0:\n",
    "#             print(counter)\n",
    "\n",
    "\n",
    "# def filter_genre_list(genres):\n",
    "#     for genre in genres:\n",
    "#         try:\n",
    "#             filter_genre(genres[genre], genre)\n",
    "#         except Exception as e:\n",
    "#             print(\"Error filtering genre: \", e)\n",
    "\n",
    "# filter_genre_list(genres)\n",
    "\n",
    "# missing files after classification\n",
    "# fma_small/098/098565.mp3\n",
    "# fma_small/098/098567.mp3\n",
    "# fma_small/098/098569.mp3\n",
    "# fma_small/108/108925.mp3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c808d5c6",
   "metadata": {},
   "source": [
    "#### **Question A4.2 (basic): Genre classification** \n",
    "\n",
    "For each track in the new fma_smaller dataset compute the Mel-Frequency Cepstral Coefficients using the librosa Python library for Music Information Retrieval (https://librosa.org/doc/main/index.html). Represent each track as a single vector consisting of the mean MFCCs vectors across the track. \n",
    "Perform k-fold cross-validation and calculate the classification report and display the confusion matrix for genre classification using this dataset. Use the Support Vector Classifier (SVC) from scikit-learn (https://scikit-learn.org/stable/) with gamma='auto'. \n",
    "\n",
    " (**Basic: 2 points**)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4bf4c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here \n",
    "import glob\n",
    "import librosa\n",
    "import soundfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import svm, metrics, neighbors, ensemble, linear_model\n",
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c83ca27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../fma_smaller\\folk\\000140.wav\n"
     ]
    }
   ],
   "source": [
    "fnames = glob.glob('../fma_smaller/*/*.wav')\n",
    "\n",
    "print(fnames[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd36df2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3996, 20)\n"
     ]
    }
   ],
   "source": [
    "genres = ['folk', 'hiphop', 'instrumental', 'rock']\n",
    "\n",
    "# allocate matrix for audio features and target \n",
    "audio_features = np.zeros((len(fnames), 20))\n",
    "target = np.zeros(len(fnames))\n",
    "\n",
    "# compute the features \n",
    "for (i,fname) in enumerate(fnames): \n",
    "    for (label,genre) in enumerate(genres): \n",
    "        if genre in fname: \n",
    "            audio, srate = librosa.load(fname)\n",
    "            mfcc_matrix = librosa.feature.mfcc(y=audio, sr=srate)\n",
    "            mean_mfcc = np.mean(mfcc_matrix,axis=1)\n",
    "            audio_features[i] = mean_mfcc\n",
    "            target[i] = label\n",
    "print(audio_features.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77b9d1f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        folk       0.63      0.58      0.60      1000\n",
      "      hiphop       0.71      0.74      0.72       997\n",
      "instrumental       0.58      0.56      0.57      1000\n",
      "        rock       0.65      0.70      0.67       999\n",
      "\n",
      "    accuracy                           0.64      3996\n",
      "   macro avg       0.64      0.64      0.64      3996\n",
      "weighted avg       0.64      0.64      0.64      3996\n",
      "\n",
      "Confusion matrix:\n",
      "[[576  74 239 111]\n",
      " [ 52 742  62 141]\n",
      " [208 110 556 126]\n",
      " [ 80 124  94 701]]\n",
      "Accuray :\n",
      "0.6443943943943944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "features = scaler.fit_transform(audio_features)\n",
    "clf_mfcc = svm.SVC(gamma='auto', kernel='linear')\n",
    "clf_mfcc.fit(features, target)\n",
    "predicted = cross_val_predict(clf_mfcc, features, target, cv=10)\n",
    "\n",
    "#print classification report\n",
    "print(metrics.classification_report(target, predicted, target_names=genres))\n",
    "\n",
    "#print confusion matrix and accuracy\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(target, predicted))\n",
    "print(\"Accuray :\\n%s\\n\" % (metrics.accuracy_score(target, predicted)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1c553f",
   "metadata": {},
   "source": [
    "#### **Question A4.3 (expected): Feature and Classifier Comparison** \n",
    "\n",
    "In this question you will explore how different features and classifiers affect the accuracy of the genre classification. In addition to the mean MFCCs across the track, consider the concatenation of the mean MFCCs and standard deviation MFCCs (this vector will be double the size of the mean MFCC vector. Do the same process with the chroma_cqt features from librosa (librosa.feature.chroma_cqt) i.e mean and the concatenetion mean_std.\n",
    "  \n",
    "Therefore you will have 4 features: meanMFCC, mean_stdMFCC, meanChromaCQT, mean_stdChroma_CQT. \n",
    "  \n",
    "In addition consider the following classifiers: Support Vector Classifier (SVC), 3-Nearest Neighbor, RandomForestClassifier, and Logistic Regression. You can use the default settings of each of these classifiers and you don't need to do any hyper-parameter tuning. \n",
    "\n",
    "  \n",
    "For each combination of configurations calculate the classification accuracy using 5-fold cross-validation. The result should be a 4 by 4 table with 16 accuracies one for each combintation of feature front-end and classifier. \n",
    "\n",
    " (**Expected: 2 points**)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d9f2012",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\godpi\\anaconda3\\envs\\music\\Lib\\site-packages\\librosa\\core\\pitch.py:101: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  return pitch_tuning(\n"
     ]
    }
   ],
   "source": [
    "# your code goes here \n",
    "\n",
    "meanMFCC = np.zeros((len(fnames), 20))\n",
    "mean_stdMFCC = np.zeros((len(fnames), 40))\n",
    "meanChromaCQT = np.zeros((len(fnames), 12))\n",
    "mean_stdChromaCQT = np.zeros((len(fnames), 24))\n",
    "\n",
    "target = np.zeros(len(fnames))\n",
    "\n",
    "# compute the features \n",
    "for (i,fname) in enumerate(fnames): \n",
    "    for (label,genre) in enumerate(genres): \n",
    "        if genre in fname: \n",
    "            audio, srate = librosa.load(fname)\n",
    "\n",
    "\n",
    "            mfcc_matrix = librosa.feature.mfcc(y=audio, sr=srate)\n",
    "            mean_mfcc = np.mean(mfcc_matrix,axis=1)\n",
    "            std_mfcc = np.std(mfcc_matrix, axis=1)\n",
    "\n",
    "            meanMFCC[i] = mean_mfcc\n",
    "            mfcc_fvec = np.concatenate([mean_mfcc, std_mfcc])\n",
    "            mean_stdMFCC[i] = mfcc_fvec\n",
    "\n",
    "            chroma_matrix = librosa.feature.chroma_cqt(y=audio, sr=srate)\n",
    "            mean_chroma = np.mean(chroma_matrix,axis=1)\n",
    "            std_chroma = np.std(chroma_matrix, axis=1)\n",
    "\n",
    "            meanChromaCQT[i] = mean_chroma\n",
    "            chroma_fvec = np.concatenate([mean_chroma, std_chroma])\n",
    "            mean_stdChromaCQT[i] = chroma_fvec\n",
    "\n",
    "\n",
    "            target[i] = label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "471438a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "meanMFCC = scaler.fit_transform(meanMFCC)\n",
    "mean_stdMFCC = scaler.fit_transform(mean_stdMFCC)\n",
    "meanChromaCQT = scaler.fit_transform(meanChromaCQT)\n",
    "mean_stdChromaCQT = scaler.fit_transform(mean_stdChromaCQT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de33b572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuray :\n",
      "0.6211211211211212\n",
      "\n",
      "Accuray :\n",
      "0.6621621621621622\n",
      "\n",
      "Accuray :\n",
      "0.48073073073073075\n",
      "\n",
      "Accuray :\n",
      "0.501001001001001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_classifier = svm.SVC(gamma='auto')\n",
    "\n",
    "\n",
    "svm_classifier.fit(meanMFCC, target)\n",
    "predicted = cross_val_predict(svm_classifier, meanMFCC, target, cv=5)\n",
    "meanMFCC_SVM_acc = metrics.accuracy_score(target, predicted)\n",
    "print(\"Accuray :\\n%s\\n\" % (metrics.accuracy_score(target, predicted)))\n",
    "\n",
    "\n",
    "svm_classifier.fit(mean_stdMFCC, target)\n",
    "predicted = cross_val_predict(svm_classifier, mean_stdMFCC, target, cv=5)\n",
    "mean_stdMFCC_SVM_acc = metrics.accuracy_score(target, predicted)\n",
    "print(\"Accuray :\\n%s\\n\" % (metrics.accuracy_score(target, predicted)))\n",
    "\n",
    "\n",
    "svm_classifier.fit(meanChromaCQT, target)\n",
    "predicted = cross_val_predict(svm_classifier, meanChromaCQT, target, cv=5)\n",
    "meanChromaCQT_SVM_acc = metrics.accuracy_score(target, predicted)\n",
    "print(\"Accuray :\\n%s\\n\" % (metrics.accuracy_score(target, predicted)))\n",
    "\n",
    "\n",
    "svm_classifier.fit(mean_stdChromaCQT, target)\n",
    "predicted = cross_val_predict(svm_classifier, mean_stdChromaCQT, target, cv=5)\n",
    "mean_stdChromaCQT_SVM_acc = metrics.accuracy_score(target, predicted)\n",
    "print(\"Accuray :\\n%s\\n\" % (metrics.accuracy_score(target, predicted)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f896a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuray :\n",
      "0.5793293293293293\n",
      "\n",
      "Accuray :\n",
      "0.6413913913913913\n",
      "\n",
      "Accuray :\n",
      "0.4451951951951952\n",
      "\n",
      "Accuray :\n",
      "0.47647647647647645\n",
      "\n"
     ]
    }
   ],
   "source": [
    "neighbor_classifier = neighbors.KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "neighbor_classifier.fit(meanMFCC, target)\n",
    "predicted = cross_val_predict(neighbor_classifier, meanMFCC, target, cv=5)\n",
    "meanMFCC_KNN_acc = metrics.accuracy_score(target, predicted)\n",
    "print(\"Accuray :\\n%s\\n\" % (metrics.accuracy_score(target, predicted)))\n",
    "\n",
    "\n",
    "neighbor_classifier.fit(mean_stdMFCC, target)\n",
    "predicted = cross_val_predict(neighbor_classifier, mean_stdMFCC, target, cv=5)\n",
    "mean_stdMFCC_KNN_acc = metrics.accuracy_score(target, predicted)\n",
    "print(\"Accuray :\\n%s\\n\" % (metrics.accuracy_score(target, predicted)))\n",
    "\n",
    "\n",
    "neighbor_classifier.fit(meanChromaCQT, target)\n",
    "predicted = cross_val_predict(neighbor_classifier, meanChromaCQT, target, cv=5)\n",
    "meanChromaCQT_KNN_acc = metrics.accuracy_score(target, predicted)\n",
    "print(\"Accuray :\\n%s\\n\" % (metrics.accuracy_score(target, predicted)))\n",
    "\n",
    "\n",
    "neighbor_classifier.fit(mean_stdChromaCQT, target)\n",
    "predicted = cross_val_predict(neighbor_classifier, mean_stdChromaCQT, target, cv=5)\n",
    "mean_stdChromaCQT_KNN_acc = metrics.accuracy_score(target, predicted)\n",
    "print(\"Accuray :\\n%s\\n\" % (metrics.accuracy_score(target, predicted)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c24b9146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuray :\n",
      "0.6466466466466466\n",
      "\n",
      "Accuray :\n",
      "0.698948948948949\n",
      "\n",
      "Accuray :\n",
      "0.5007507507507507\n",
      "\n",
      "Accuray :\n",
      "0.541041041041041\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_forest_classifier = ensemble.RandomForestClassifier()\n",
    "\n",
    "random_forest_classifier.fit(meanMFCC, target)\n",
    "predicted = cross_val_predict(random_forest_classifier, meanMFCC, target, cv=5)\n",
    "meanMFCC_RF_acc = metrics.accuracy_score(target, predicted)\n",
    "print(\"Accuray :\\n%s\\n\" % (metrics.accuracy_score(target, predicted)))\n",
    "\n",
    "\n",
    "random_forest_classifier.fit(mean_stdMFCC, target)\n",
    "predicted = cross_val_predict(random_forest_classifier, mean_stdMFCC, target, cv=5)\n",
    "mean_stdMFCC_RF_acc = metrics.accuracy_score(target, predicted)\n",
    "print(\"Accuray :\\n%s\\n\" % (metrics.accuracy_score(target, predicted)))\n",
    "\n",
    "\n",
    "random_forest_classifier.fit(meanChromaCQT, target)\n",
    "predicted = cross_val_predict(random_forest_classifier, meanChromaCQT, target, cv=5)\n",
    "meanChromaCQT_RF_acc = metrics.accuracy_score(target, predicted)\n",
    "print(\"Accuray :\\n%s\\n\" % (metrics.accuracy_score(target, predicted)))\n",
    "\n",
    "\n",
    "random_forest_classifier.fit(mean_stdChromaCQT, target)\n",
    "predicted = cross_val_predict(random_forest_classifier, mean_stdChromaCQT, target, cv=5)\n",
    "mean_stdChromaCQT_RF_acc = metrics.accuracy_score(target, predicted)\n",
    "print(\"Accuray :\\n%s\\n\" % (metrics.accuracy_score(target, predicted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e261ce4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\godpi\\anaconda3\\envs\\music\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\godpi\\anaconda3\\envs\\music\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\godpi\\anaconda3\\envs\\music\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\godpi\\anaconda3\\envs\\music\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\godpi\\anaconda3\\envs\\music\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\godpi\\anaconda3\\envs\\music\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuray :\n",
      "0.6333833833833834\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\godpi\\anaconda3\\envs\\music\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\godpi\\anaconda3\\envs\\music\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\godpi\\anaconda3\\envs\\music\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\godpi\\anaconda3\\envs\\music\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\godpi\\anaconda3\\envs\\music\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuray :\n",
      "0.6779279279279279\n",
      "\n",
      "Accuray :\n",
      "0.4647147147147147\n",
      "\n",
      "Accuray :\n",
      "0.4954954954954955\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logistic_classifier = linear_model.LogisticRegression()\n",
    "\n",
    "logistic_classifier.fit(meanMFCC, target)\n",
    "predicted = cross_val_predict(logistic_classifier, meanMFCC, target, cv=5)\n",
    "meanMFCC_LR_acc = metrics.accuracy_score(target, predicted)\n",
    "print(\"Accuray :\\n%s\\n\" % (metrics.accuracy_score(target, predicted)))\n",
    "\n",
    "\n",
    "logistic_classifier.fit(mean_stdMFCC, target)\n",
    "predicted = cross_val_predict(logistic_classifier, mean_stdMFCC, target, cv=5)\n",
    "mean_stdMFCC_LR_acc = metrics.accuracy_score(target, predicted)\n",
    "print(\"Accuray :\\n%s\\n\" % (metrics.accuracy_score(target, predicted)))\n",
    "\n",
    "\n",
    "logistic_classifier.fit(meanChromaCQT, target)\n",
    "predicted = cross_val_predict(logistic_classifier, meanChromaCQT, target, cv=5)\n",
    "meanChromaCQT_LR_acc = metrics.accuracy_score(target, predicted)\n",
    "print(\"Accuray :\\n%s\\n\" % (metrics.accuracy_score(target, predicted)))\n",
    "\n",
    "\n",
    "logistic_classifier.fit(mean_stdChromaCQT, target)\n",
    "predicted = cross_val_predict(logistic_classifier, mean_stdChromaCQT, target, cv=5)\n",
    "mean_stdChromaCQT_LR_acc = metrics.accuracy_score(target, predicted)\n",
    "print(\"Accuray :\\n%s\\n\" % (metrics.accuracy_score(target, predicted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49bae054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>SVM</th>\n",
       "      <th>KNN</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Logistic Regression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MFCC</td>\n",
       "      <td>0.621121</td>\n",
       "      <td>0.579329</td>\n",
       "      <td>0.646647</td>\n",
       "      <td>0.633383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MFCC + STD</td>\n",
       "      <td>0.662162</td>\n",
       "      <td>0.641391</td>\n",
       "      <td>0.698949</td>\n",
       "      <td>0.677928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chroma CQT</td>\n",
       "      <td>0.480731</td>\n",
       "      <td>0.445195</td>\n",
       "      <td>0.500751</td>\n",
       "      <td>0.464715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chroma CQT + STD</td>\n",
       "      <td>0.501001</td>\n",
       "      <td>0.476476</td>\n",
       "      <td>0.541041</td>\n",
       "      <td>0.495495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Feature       SVM       KNN  Random Forest  Logistic Regression\n",
       "0              MFCC  0.621121  0.579329       0.646647             0.633383\n",
       "1        MFCC + STD  0.662162  0.641391       0.698949             0.677928\n",
       "2        Chroma CQT  0.480731  0.445195       0.500751             0.464715\n",
       "3  Chroma CQT + STD  0.501001  0.476476       0.541041             0.495495"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_columns = ['Feature', 'SVM', 'KNN', 'Random Forest', 'Logistic Regression']\n",
    "\n",
    "classifier_acc = np.zeros([4,5])\n",
    "\n",
    "classifier_acc[0][1] = meanMFCC_SVM_acc\n",
    "classifier_acc[0][2] = meanMFCC_KNN_acc\n",
    "classifier_acc[0][3] = meanMFCC_RF_acc\n",
    "classifier_acc[0][4] = meanMFCC_LR_acc\n",
    "\n",
    "classifier_acc[1][1] = mean_stdMFCC_SVM_acc\n",
    "classifier_acc[1][2] = mean_stdMFCC_KNN_acc\n",
    "classifier_acc[1][3] = mean_stdMFCC_RF_acc\n",
    "classifier_acc[1][4] = mean_stdMFCC_LR_acc\n",
    "\n",
    "classifier_acc[2][1] = meanChromaCQT_SVM_acc\n",
    "classifier_acc[2][2] = meanChromaCQT_KNN_acc\n",
    "classifier_acc[2][3] = meanChromaCQT_RF_acc\n",
    "classifier_acc[2][4] = meanChromaCQT_LR_acc\n",
    "\n",
    "classifier_acc[3][1] = mean_stdChromaCQT_SVM_acc\n",
    "classifier_acc[3][2] = mean_stdChromaCQT_KNN_acc\n",
    "classifier_acc[3][3] = mean_stdChromaCQT_RF_acc\n",
    "classifier_acc[3][4] = mean_stdChromaCQT_LR_acc\n",
    "\n",
    "\n",
    "classification_accuracy = pd.DataFrame(data=classifier_acc, columns = num_columns)\n",
    "classification_accuracy['Feature'] = ['MFCC', 'MFCC + STD', 'Chroma CQT', 'Chroma CQT + STD']\n",
    "\n",
    "classification_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee7586f",
   "metadata": {},
   "source": [
    "#### **Question A4.4 (expected): Misclassification Audio** \n",
    "\n",
    "In this question the goal is to listen to some of the misclassification. Write a function \n",
    "**misclassification_audio(ground_label, predicted_label)** that takes as input a ground truth label and a predicted label and returns an audio file with a maximum of 10 misclassified audio tracks that had the ground truth label but were predicted as the predicted_label. For example let's say that \n",
    "there are 23 tracks that were originally labeled as Instrumental but were predicted as HipHop. The result of the function will be an audio file consisting of 10 6-second audio tracks that were misclassifed that way. By listening to this one minute audio file you will get a sense of what type of Instrumental tracks were misclassifed as HipHop. \n",
    "\n",
    " (**Expected: 2 points**)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bdcaa29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def misclassification_audio(ground_label, predicted_label):\n",
    "    count = 0\n",
    "    clips = []\n",
    "    for i in range(len(fnames)):\n",
    "        if target[i] == ground_label and predicted[i] == predicted_label:\n",
    "            audio, srate = librosa.load(fnames[i])\n",
    "            clips.append(audio)\n",
    "            count += 1\n",
    "        if count == 10:\n",
    "            break\n",
    "    \n",
    "    sum_audio = np.concatenate(clips)\n",
    "    soundfile.write('misclassified_audio.wav', sum_audio, srate)\n",
    "\n",
    "#2=instrumental, 1=hiphop\n",
    "misclassification_audio(2,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eec7c58",
   "metadata": {},
   "source": [
    "#### **Question A4.5 (advanced): Misclassification Audio** \n",
    "\n",
    "For this question you will need to be able to run the musicnn auto-tagger developed by Jordi Pons: https://github.com/jordipons/musicnn\n",
    "\n",
    "For each track in the 4 genres we have been exploring in this question calculate the topN (N=10) tags using the MSD_musicnn model. Find the 15 most 'popular' tags that is the tags that appear most times in the tracks we are examining. Convert each track to a binary bag of words representation using these 15 most popular tags. Now each track should be represented by 15 binary numbers.\n",
    "\n",
    "Adapt the code from performing classification based on lyrics shown at the bottom of this notebook to perform Naive Bayes classification using the tag bag-of-words representation:\n",
    "\n",
    "https://github.com/gtzan/csc421_tzanetakis/blob/main/csc421_tzanetakis_quantifying_uncertainty.ipynb\n",
    "\n",
    " (**Advanced: 2 points**)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d3c738",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
